{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.7.0+cu110\n",
      "  Using cached https://download.pytorch.org/whl/cu110/torch-1.7.0%2Bcu110-cp38-cp38-win_amd64.whl (2046.8 MB)\n",
      "Collecting torchvision==0.8.1+cu110\n",
      "  Using cached https://download.pytorch.org/whl/cu110/torchvision-0.8.1%2Bcu110-cp38-cp38-win_amd64.whl (1.6 MB)\n",
      "Collecting torchaudio===0.7.0\n",
      "  Using cached https://download.pytorch.org/whl/torchaudio-0.7.0-cp38-none-win_amd64.whl (103 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\calypso\\anaconda3\\lib\\site-packages (from torch==1.7.0+cu110) (3.7.4.3)\n",
      "Collecting dataclasses\n",
      "  Using cached dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: future in c:\\users\\calypso\\anaconda3\\lib\\site-packages (from torch==1.7.0+cu110) (0.18.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\calypso\\anaconda3\\lib\\site-packages (from torch==1.7.0+cu110) (1.19.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\calypso\\anaconda3\\lib\\site-packages (from torchvision==0.8.1+cu110) (8.0.1)\n",
      "Installing collected packages: dataclasses, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.8.1\n",
      "    Uninstalling torch-1.8.1:\n",
      "      Successfully uninstalled torch-1.8.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.9.1\n",
      "    Uninstalling torchvision-0.9.1:\n",
      "      Successfully uninstalled torchvision-0.9.1\n",
      "Successfully installed dataclasses-0.6 torch-1.7.0+cu110 torchaudio-0.7.0 torchvision-0.8.1+cu110\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.7.0+cu110 torchvision==0.8.1+cu110 torchaudio===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение нейросети, распознающей рукописные цифры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# import standard PyTorch modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# import torchvision module to handle image manipulation\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.load('./data/train.pt')\n",
    "test = torch.load('./data/test.pt')\n",
    "valid = torch.load('./data/valid.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "train_loader = DataLoader(dataset=train, batch_size=1000, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test, batch_size=1000, shuffle=False)\n",
    "valid_loader = DataLoader(dataset=valid, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "             nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
    "             nn.ReLU(),\n",
    "             nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "             nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "             nn.ReLU(),\n",
    "             nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.bn1 = nn.BatchNorm1d(7 * 7 * 64)\n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 1000)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.drop_out2 = nn.Dropout(0.1)\n",
    "        self.bn2 = nn.BatchNorm1d(1000)\n",
    "        self.fc2 = nn.Linear(1000, 500)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.drop_out3 = nn.Dropout(0.2)\n",
    "        self.bn3 = nn.BatchNorm1d(500)\n",
    "        self.fc3 = nn.Linear(500, 10)\n",
    "        #в архитектуре на выходе нет софтмакса, так как он вычисляет внутри nn.CrossEntropyLoss()\n",
    "        #и учитывается во время подсчета accuracy\n",
    "      \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.bn1(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.drop_out2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.drop_out3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "num_classes = 10\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Train Loss(mean): 0.1764, Test Loss: 0.0557\n",
      "Epoch [2/200], Train Loss(mean): 0.0436, Test Loss: 0.0461\n",
      "Epoch [3/200], Train Loss(mean): 0.0362, Test Loss: 0.0448\n",
      "Epoch [4/200], Train Loss(mean): 0.0342, Test Loss: 0.0445\n",
      "Epoch [5/200], Train Loss(mean): 0.0344, Test Loss: 0.0447\n",
      "Epoch [6/200], Train Loss(mean): 0.0343, Test Loss: 0.0447\n",
      "Epoch [7/200], Train Loss(mean): 0.0339, Test Loss: 0.0442\n",
      "Epoch [8/200], Train Loss(mean): 0.0343, Test Loss: 0.0439\n",
      "Epoch [9/200], Train Loss(mean): 0.0344, Test Loss: 0.0448\n",
      "Epoch [10/200], Train Loss(mean): 0.0339, Test Loss: 0.0433\n",
      "Epoch [11/200], Train Loss(mean): 0.0345, Test Loss: 0.0449\n",
      "Epoch [12/200], Train Loss(mean): 0.0338, Test Loss: 0.0438\n",
      "Epoch [13/200], Train Loss(mean): 0.0342, Test Loss: 0.0438\n",
      "Epoch [14/200], Train Loss(mean): 0.0346, Test Loss: 0.0439\n",
      "Epoch [15/200], Train Loss(mean): 0.0338, Test Loss: 0.0454\n",
      "Epoch [16/200], Train Loss(mean): 0.0342, Test Loss: 0.0440\n",
      "Epoch [17/200], Train Loss(mean): 0.0338, Test Loss: 0.0442\n",
      "Epoch [18/200], Train Loss(mean): 0.0339, Test Loss: 0.0447\n",
      "Epoch [19/200], Train Loss(mean): 0.0343, Test Loss: 0.0432\n",
      "Epoch [20/200], Train Loss(mean): 0.0340, Test Loss: 0.0449\n",
      "Epoch [21/200], Train Loss(mean): 0.0345, Test Loss: 0.0448\n",
      "Epoch [22/200], Train Loss(mean): 0.0344, Test Loss: 0.0452\n",
      "Epoch [23/200], Train Loss(mean): 0.0341, Test Loss: 0.0443\n",
      "Epoch [24/200], Train Loss(mean): 0.0343, Test Loss: 0.0446\n",
      "Epoch [25/200], Train Loss(mean): 0.0338, Test Loss: 0.0444\n",
      "Epoch [26/200], Train Loss(mean): 0.0345, Test Loss: 0.0439\n",
      "Epoch [27/200], Train Loss(mean): 0.0339, Test Loss: 0.0452\n",
      "Epoch [28/200], Train Loss(mean): 0.0336, Test Loss: 0.0445\n",
      "Epoch [29/200], Train Loss(mean): 0.0342, Test Loss: 0.0448\n",
      "Epoch [30/200], Train Loss(mean): 0.0343, Test Loss: 0.0441\n",
      "Epoch [31/200], Train Loss(mean): 0.0341, Test Loss: 0.0454\n",
      "Epoch [32/200], Train Loss(mean): 0.0339, Test Loss: 0.0446\n",
      "Epoch [33/200], Train Loss(mean): 0.0336, Test Loss: 0.0438\n",
      "Epoch [34/200], Train Loss(mean): 0.0344, Test Loss: 0.0442\n",
      "Epoch [35/200], Train Loss(mean): 0.0344, Test Loss: 0.0440\n",
      "Epoch [36/200], Train Loss(mean): 0.0343, Test Loss: 0.0443\n",
      "Epoch [37/200], Train Loss(mean): 0.0340, Test Loss: 0.0437\n",
      "Epoch [38/200], Train Loss(mean): 0.0338, Test Loss: 0.0446\n",
      "Epoch [39/200], Train Loss(mean): 0.0342, Test Loss: 0.0447\n",
      "Epoch [40/200], Train Loss(mean): 0.0339, Test Loss: 0.0439\n",
      "Epoch [41/200], Train Loss(mean): 0.0342, Test Loss: 0.0440\n",
      "Epoch [42/200], Train Loss(mean): 0.0338, Test Loss: 0.0440\n",
      "Epoch [43/200], Train Loss(mean): 0.0343, Test Loss: 0.0442\n",
      "Finished\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "eps = 3e-4\n",
    "eps_counter = 0\n",
    "EPS_BORDER = 3\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = []\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images.size()\n",
    "        # Run the forward pass\n",
    "        images = images.float().to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images.unsqueeze(1))\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        images = test.tensors[0].float().to(device)\n",
    "        labels = test.tensors[1].to(device)\n",
    "        output = model(images.unsqueeze(1))  \n",
    "        loss = criterion(output, labels)\n",
    "        test_losses.append(loss.cpu().detach().numpy())\n",
    "            \n",
    "    train_losses.append(np.mean(train_loss)) \n",
    "    print('Epoch [{}/{}], Train Loss(mean): {:.4f}, Test Loss: {:.4f}'\n",
    "                  .format(epoch + 1, num_epochs, np.mean(train_loss),\n",
    "                          test_losses[epoch]))\n",
    "    #early stopper\n",
    "    if len(test_losses) >= 2 and np.abs(test_losses[-1] - test_losses[-2]) < eps:\n",
    "        eps_counter = eps_counter + 1\n",
    "    else:\n",
    "        eps_counter = 0\n",
    "    if eps_counter >= EPS_BORDER:\n",
    "        break\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjg0lEQVR4nO3de5BcZ33m8e+vT3dP91ykGUkjy5ZkS7ZlG4UF21EcgxMIYHalQCF2K6m1K2wosrUuV3Cws2GJQ2qX3SR7qS0qIdQ6aL1gNtlQeFlDZVWUYmMgQMJiovGFGCHLlmRjja6j69z7+ts/3jMzPa2W5kgaeUann09V1+k+t3777dPPefvt0+eYuyMiIumVWegCiIjI5aWgFxFJOQW9iEjKKehFRFJOQS8iknLZhS5AKytWrPB169YtdDFERK4Yzz777HF37281bVEG/bp16xgYGFjoYoiIXDHM7Kfnmpao68bMNpvZHjPba2YPt5h+i5n9wMxKZvbxpmm/bWa7zOzHZvZlMytc+EsQEZGLNWfQm1kEPAJsATYC95rZxqbZTgIfAz7dtOzqePwmd38zEAH3zEO5RUQkoSQt+juAve6+393LwOPA1sYZ3P2Yu+8EKi2WzwJFM8sCncChSyyziIhcgCRBvxo40PB4MB43J3c/SGjlvw4cBs64+zdazWtm95nZgJkNDA0NJVm9iIgkkCTorcW4RCfIMbM+Qut/PXAN0GVmH2o1r7s/6u6b3H1Tf3/LH45FROQiJAn6QWBtw+M1JO9+uRt41d2H3L0CfA14+4UVUURELkWSoN8JbDCz9WaWJ/yYuj3h+l8H7jSzTjMz4D3A7osrqoiIXIw5j6N396qZPQA8RThq5jF332Vm98fTt5nZKmAAWALUzewhYKO7/9DMngCeA6rA88Cjl+elwGe/9QpvXdvLO29S14+IyJREf5hy9x3AjqZx2xruHyF06bRa9lPApy6hjIn99+/u4947rlXQi4g0SNW5bor5iIlKbaGLISKyqKQq6As5Bb2ISLNUBX1nPmJSQS8iMkuqgr6Yi5goK+hFRBqlKujVdSMicrZUBX0xrxa9iEizdAW9WvQiImdR0IuIpFyqgr6Qj5go1xe6GCIii0qqgr6Y0+GVIiLNUhf0E5Ua7onOoiwi0hbSFfT5iFrdqdQU9CIiU1IV9IVcBKAfZEVEGqQq6DvzIejVTy8iMiNVQV+catHrT1MiItNSFfRTXTfjCnoRkWmpCvpiXn30IiLN0hX0OfXRi4g0S2XQq49eRGRGoqA3s81mtsfM9prZwy2m32JmPzCzkpl9vGlar5k9YWYvmdluM3vbfBW+WTEfXo66bkREZsx5cXAzi4BHgPcCg8BOM9vu7j9pmO0k8DHggy1W8afAk+7+K2aWBzovudTnoOPoRUTOlqRFfwew1933u3sZeBzY2jiDux9z951ApXG8mS0B3gF8IZ6v7O6n56PgraiPXkTkbEmCfjVwoOHxYDwuieuBIeCLZva8mX3ezLpazWhm95nZgJkNDA0NJVz9bNNH3aiPXkRkWpKgtxbjkp5MJgvcDnzO3W8DxoCz+vgB3P1Rd9/k7pv6+/sTrn62QlZdNyIizZIE/SCwtuHxGuBQwvUPAoPu/sP48ROE4L8sMhmjkMso6EVEGiQJ+p3ABjNbH/+Yeg+wPcnK3f0IcMDMbo5HvQf4yXkWuWTFXMSkum5ERKbNedSNu1fN7AHgKSACHnP3XWZ2fzx9m5mtAgaAJUDdzB4CNrr7MPBbwJfincR+4COX56UExVykUyCIiDSYM+gB3H0HsKNp3LaG+0cIXTqtln0B2HTxRbwwhbyuGysi0ihV/4wFXU5QRKRZKoNeLXoRkRnpC/p8pOPoRUQapC7oC7mIiUp9oYshIrJopC7o1UcvIjJbKoNeXTciIjPSF/Q6vFJEZBYFvYhIyqUv6HMR5WqdWj3peddERNItlUEPOoOliMiU1AV9QeekFxGZJXVBr6tMiYjMltqgV9eNiEiQvqDPh5ekrhsRkSB1QV9Qi15EZJbUBb26bkREZktf0MdH3ehygiIiQfqCXi16EZFZEgW9mW02sz1mttfMHm4x/RYz+4GZlczs4y2mR2b2vJl9fT4KfT4KehGR2eYMejOLgEeALcBG4F4z29g020ngY8Cnz7GaB4Hdl1DOxIr6w5SIyCxJWvR3AHvdfb+7l4HHga2NM7j7MXffCVSaFzazNcD7gM/PQ3nnNH3UjYJeRARIFvSrgQMNjwfjcUl9BvgE8IZc9ikXZchFpq4bEZFYkqC3FuMSnRrSzN4PHHP3ZxPMe5+ZDZjZwNDQUJLVn1NBFwgXEZmWJOgHgbUNj9cAhxKu/y7gA2b2GqHL591m9petZnT3R919k7tv6u/vT7j61nQ5QRGRGUmCfiewwczWm1keuAfYnmTl7v577r7G3dfFy33b3T900aVNqJjX5QRFRKZk55rB3atm9gDwFBABj7n7LjO7P56+zcxWAQPAEqBuZg8BG919+PIV/dyK6roREZk2Z9ADuPsOYEfTuG0N948QunTOt47vAN+54BJehNBH/4b89isisuil7p+xEPfRq+tGRARIa9DrAuEiItPSGfS5iPFydaGLISKyKKQz6PMRk+qjFxEB0hr0OupGRGRaOoNex9GLiExLZdBPnQLBPdGZGkREUi2VQT91TvpSVf30IiIpDfrwstR9IyKS1qDP6ypTIiJTUhn0BV1OUERkWiqDvqirTImITEtn0MddNzonvYhIWoM+btGPq0UvIpLSoNePsSIi09IZ9Dl13YiITEln0Of1Y6yIyJR0Br0OrxQRmZbKoNdx9CIiMxIFvZltNrM9ZrbXzB5uMf0WM/uBmZXM7OMN49ea2d+Y2W4z22VmD85n4c+lI5vBDF1OUESEBBcHN7MIeAR4LzAI7DSz7e7+k4bZTgIfAz7YtHgV+B13f87MeoBnzezppmXnnZnpnPQiIrEkLfo7gL3uvt/dy8DjwNbGGdz9mLvvBCpN4w+7+3Px/RFgN7B6Xko+BwW9iEiQJOhXAwcaHg9yEWFtZuuA24AfnmP6fWY2YGYDQ0NDF7r6sxRyERNlnaZYRCRJ0FuLcRd0RQ8z6wa+Cjzk7sOt5nH3R919k7tv6u/vv5DVt1TMR0xUdIFwEZEkQT8IrG14vAY4lPQJzCxHCPkvufvXLqx4F6+Y0+UERUQgWdDvBDaY2XozywP3ANuTrNzMDPgCsNvd//jii3nh1EcvIhLMedSNu1fN7AHgKSACHnP3XWZ2fzx9m5mtAgaAJUDdzB4CNgJvAf4F8KKZvRCv8pPuvmPeX0mTYj7i9ERl7hlFRFJuzqAHiIN5R9O4bQ33jxC6dJr9Ha37+C+7Yi7iyJnJhXhqEZFFJZX/jIWpH2PVdSMiktqgL6iPXkQESHHQF3ORToEgIkKagz6fUYteRIQ0B30uolp3KjX9O1ZE2ltqg16nKhYRCVIb9LrKlIhIkN6gzynoRUSgHYJeXTci0ubSG/R5Bb2ICKQ56OMWvY6lF5F2l96gV4teRARIc9Crj15EBEhx0Bd01I2ICJDioJ/quplUi15E2lx6g15dNyIiQIqDfqrrZlxdNyLS5lIb9FHGyGd1BksRkdQGPeic9CIikDDozWyzme0xs71m9nCL6beY2Q/MrGRmH7+QZS+noq4yJSIyd9CbWQQ8AmwBNgL3mtnGptlOAh8DPn0Ry142nfmIiYrORy8i7S1Ji/4OYK+773f3MvA4sLVxBnc/5u47gcqFLns5FXKRjqMXkbaXJOhXAwcaHg/G45JIvKyZ3WdmA2Y2MDQ0lHD151fMRzqOXkTaXpKgtxbjPOH6Ey/r7o+6+yZ339Tf359w9eenPnoRkWRBPwisbXi8BjiUcP2XsuwlU9eNiEiyoN8JbDCz9WaWB+4Btidc/6Use8nUdSMiAtm5ZnD3qpk9ADwFRMBj7r7LzO6Pp28zs1XAALAEqJvZQ8BGdx9utexlei1nKeYy+mesiLS9OYMewN13ADuaxm1ruH+E0C2TaNk3ivroRURS/s/YQl5BLyKS6qAv5iLK1Tq1etKDhERE0if1QQ86J72ItLdUB32nrhsrIpLuoNflBEVEUh70upygiEjag16XExQRaZOgV9eNiLSxVAd9QT/GioikO+jVohcRaZegV4teRNpYuoNeXTciIukOeh1HLyKS8qDXKRBERFIe9LnIiDKmrhsRaWupDnozozMXMVGuL3RRREQWTKqDHnROehGR1Ad9MafrxopIe0sU9Ga22cz2mNleM3u4xXQzs8/G0//BzG5vmPbbZrbLzH5sZl82s8J8voC5FHORjroRkbY2Z9CbWQQ8AmwBNgL3mtnGptm2ABvi233A5+JlVwMfAza5+5sJFwi/Z95Kn0AhHzGuFr2ItLEkLfo7gL3uvt/dy8DjwNamebYCf+HBM0CvmV0dT8sCRTPLAp3AoXkqeyLFXIZJtehFpI0lCfrVwIGGx4PxuDnncfeDwKeB14HDwBl3/8bFF/fCFXP6MVZE2luSoLcW45qvtt1yHjPrI7T21wPXAF1m9qGWT2J2n5kNmNnA0NBQgmIlU9RRNyLS5pIE/SCwtuHxGs7ufjnXPHcDr7r7kLtXgK8Bb2/1JO7+qLtvcvdN/f39Scs/p4J+jBWRNpck6HcCG8xsvZnlCT+mbm+aZzvw6/HRN3cSumgOE7ps7jSzTjMz4D3A7nks/5x0eKWItLvsXDO4e9XMHgCeIhw185i77zKz++Pp24AdwC8De4Fx4CPxtB+a2RPAc0AVeB549HK8kHNRH72ItLs5gx7A3XcQwrxx3LaG+w589BzLfgr41CWU8ZJ0xn307k74UiEi0l5S/8/YQj7CHUpVne9GRNpT6oNepyoWkXbXNkGvfnoRaVfpD/r4coLjOsRSRNpU6oNelxMUkXaX+qBXH72ItLv0B31effQi0t7SH/TquhGRNpf6oC/oqBsRaXOpD/qprhv10YtIu0p90Heq60ZE2lzqg37mx1idAkFE2lPqg74jG16i+uhFpF2lPujNLJyquFxd6KKIiCyI1Ac96HKCItLe2iPocxETZfXRi0h7aougL+QyOrxSRNpWWwS9um5EpJ21R9DnIh1HLyJtK1HQm9lmM9tjZnvN7OEW083MPhtP/wczu71hWq+ZPWFmL5nZbjN723y+gCQKukC4iLSxOYPezCLgEWALsBG418w2Ns22BdgQ3+4DPtcw7U+BJ939FuCtwO55KPcFKeYi9dGLSNtK0qK/A9jr7vvdvQw8Dmxtmmcr8BcePAP0mtnVZrYEeAfwBQB3L7v76fkrfjKd6qMXkTaWJOhXAwcaHg/G45LMcz0wBHzRzJ43s8+bWVerJzGz+8xswMwGhoaGEr+AJIp59dGLSPtKEvTWYpwnnCcL3A58zt1vA8aAs/r4Adz9UXff5O6b+vv7ExQrOfXRi0g7SxL0g8DahsdrgEMJ5xkEBt39h/H4JwjB/4bSUTci0s6SBP1OYIOZrTezPHAPsL1pnu3Ar8dH39wJnHH3w+5+BDhgZjfH870H+Ml8FT6pYi6iWncqNf07VkTaT3auGdy9amYPAE8BEfCYu+8ys/vj6duAHcAvA3uBceAjDav4LeBL8U5if9O0N0TjdWNzUVv8dUBEZNqcQQ/g7jsIYd44blvDfQc+eo5lXwA2XXwRE6rX4cX/AyvfBFe/ZdakqcsJTpZrLCnkLntRREQWk/Q0b8sj8OTD8I3fB5/9W3FR140VkTaWnqAvLIV3/i68+j3Y+81Zkxq7bkRE2k16gh5g029A33p4+t9BfSbUi7purIi0sXQFfTYPd38Kjv0EXvjS9OiCum5EpI2lK+gBNn4Q1vwc/M1/gvIYMNN1o/PdiEg7Sl/Qm8F7/xBGDsMP/gwI57oBdJUpEWlL6Qt6gOveBre8H77/GRgdmu6jH9cFwkWkDaUz6AHu/vdQmYDv/peZ4+jVdSMibSi9Qb9iA2z6CAx8kc6R/YB+jBWR9pTeoIdwXH2uSPG7fwSoj15E2lO6g757Jdz1EJk9X+dt2ZfVoheRtpTuoAd4229C9yoezn6JSf0YKyJtKP1Bn++Cd/8+b+UVbh568qzz4IiIpF36gx7g1l9jn13HvYN/CH/yM/DVfwUDX4ShlxX8l9vIETj4LNQqC10SmQ/Dh+HgczA5vNAlkQuQ6DTFV7xMxCd7/ogP5Hbya6sOwKvfhRe/EqZ1roDr3g6rfxY6l4eTozXfOnqgVobKJFTGoToZDt2sTEB1IuwsLNN0szDMdUJXf1h3dInVPXEKjr0Ex1+GvnVw7dvCaR+SKI3Cvm/DqVfhqjfDNbdB57JLK08r7nD4R/DyU/DyX8Oh58P4jiWw/h1w491w43ug99qLW3+1DGPHYPRoqNO+dcmXrVXCSe9e/V54nO2AKAdRR3w/H27lMZg4Gep7PB5OnArjcl3Qf3PD7RZYdn1Yz7nqozwWtpUoC9lCeL7MRbaxxk7AgWfgp/8PXn8Ghg+FOli2Ptz61ofyLFsPxb7w/KURKA3D5JmZW2kk1N+y9bB07bnLP3YcXvtbePVvQ72deGVm2pLVsOKmUAeN9XE5tqvLoTQC4yfCdlEthc/41K1aDtvE8hug5+rweb6CmS/CFu2mTZt8YGBgXtf5T//s+3R3ZPlf//Lnw8Z/cj/89Pvw2vfDh+bM6/P6fGez8AHo6o9vK8IHraMn3PLxsKM7DKM8nNgHx3bD0O4wHDk8e5X5HrjhXbDhH4dbz1Wzp58ZhD1/DS8/GT6ktfLs6X3rYfXtcM3tYUe36h+FjdvrM7d6reGxhyHeNK4GR3eF53rlG3E5LZyK4qZ/EoLo1e+FHc2Z+BryK26CG94D634BMlEchuNQHofKWDwcD0EzenTmNnFq9mtYfmN47TfeDdfdBbnC7OnVctix7/oreOnrMHkaMtmwE26uj2YdS0JYFvvCe1foDeFwfA+cbtheMllYdgP0rAqvozwah+toOH22tzjaK5MLdZ3tCOFfXAbd/dB9Vdg+uq8KBxN09YfXPRXsx/eE5aN8eM96rwtlObkfRo/Mfo5cV9wQmeNoM4tg6ZqZHUbfOhg5GgL+6I/DPPnu0CBa/47wnCf2wtCeUJ6hPeG9mlLoDQG57PpQL8uuD4/71oU6Hz8R3tfxE2FHOh7fr9dCV2uuE/Kdofz5zjDOMrN3VI23ykQI495r49vaMFyyJjSEKpOhcXRsdzgP1tRwalucS64rlH/5jeGw7eU3hjowg3q14VaLb9WZhl5zw88yYccyva1P3SbCMMrDuz6ZrFzNb6PZs+7e8tofbRP0v/b5Zxgr1firj97VeoZzbUSTZ8IHNspBrhhu2XiYK4T7lmkRgPVwMZTKGIwNxYF1bOb+2LGwcZdGoX6ebo1sMbSUVr4p3PrfBCtuDBvry0/BK0/DSHwJ36tvDaEHoTV95MVwf9n1cNMWuHkLrNwIR18MX78PPhta3MMH56eS8z1w47vhps1w43tDcDVyDx+4vd8Kp5L+6ffDt6NWLBM+YJ3LQoB2r4zDbyoAV4aA2/t0aG3WSiEgpr419Fwdgv2lHVA6E0L75i2wcWvYweQKoTy1Sli2Wg7DWjmEWmHpuVu5EAL9+Cuzw270aFh2aufd0TPzONcZAqA6GbcYS3ErshSCaOJkvDM7Fm610uznKyyFtXfCtXeGb3LX3Hb2Tq08Bqdeg5OvhuAfORyet9W31Hx32BZPvTqzzNT98RNh57P250N9rn8nXHPrueujXofhwVAHQ3vg5L7w/Cf2x2E6V8YYFHvDDnNqR3/e2TPxTrg3fp86wmsdPti0U7Owoxw/PjM+k5v9eeq5Ov4mF3+zi3Iz3+7KY2GHdmJf+CZzYm/Y5ubacV6sTC7scB984aIWV9AD//XJl/iz7+zjz3/jDt55U//cC7xR3MMHvjwavl6X4tZgdTK0rnqvCy3e8y1/9Mdx6H8DBneG8Wt/PgTbTVtCK+R8Xz1HjsKh50Kr3D3Mm4niFkjUomUSt06wmXFL14YWddKuJAitmCM/Ds813ZKLh9mO5F+Xy+Pw2t+F1//KN+D0T8P4wlK4+X1xuL8rrPNK4B4aGKNxF1WxL+ygL7a750JNDs9827hU1VK8I9kfhtlC+CbbuXzmW22xb/Y27h62jfLYzLc7r8/eSbWqi1olhP3p1+H0gTAcPhjCfOWb4KqfOX83W9LXc/LVsAMzC5+PTLbhFs28luZvwlPfkKN8/I2lGLb1XHz/UsqFgh4Ipz/4wH/7O06NV3jywV9kefcV8qG/UOMnw/BK6Sedb+6h5TVyOLSAL2THI3IFO1/QJ2oimNlmM9tjZnvN7OEW083MPhtP/wczu71pemRmz5vZ1y/uJVy6Qi7iT++5jTPjFX73qy+yGHdw86JzWfuGPIRW1ooNoctBIS8CJAh6M4uAR4AtwEbgXjPb2DTbFmBDfLsP+FzT9AeB3Zdc2kv0pquX8InNN/PN3Uf58t8n/CFGROQKl6RFfwew1933u3sZeBzY2jTPVuAvPHgG6DWzqwHMbA3wPuDz81jui/Ybd63nFzes4A++vot9Q6MLXRwRkcsuSdCvBhqbv4PxuKTzfAb4BHDen6rN7D4zGzCzgaGhoQTFujiZjPHpX30rxVzEQ4+/QLmqE52JSLolCfpWhz40d3C3nMfM3g8cc/dn53oSd3/U3Te5+6b+/st7VMxVSwr853/2Fl48eIY/+ebLl/W5REQWWpKgHwTWNjxeAxxKOM9dwAfM7DVCl8+7zewvL7q082jzm1dxz8+tZdt39/HM/hMLXRwRkcsmSdDvBDaY2XozywP3ANub5tkO/Hp89M2dwBl3P+zuv+fua9x9Xbzct939Q/P5Ai7Fv33/RtYt7+Jf/+8XODOuc7GISDrNGfTuXgUeAJ4iHDnzFXffZWb3m9n98Ww7gP3AXuB/AL95mco7r7o6snzmn9/KsZES/+aJHzE0Upp7IRGRK0zb/GHqfB793j7+046XyGaMX7p5Jb+6aQ3vunkl+Wx7nNxTRK585/vDVHucvXIO973jBt5180qeeHaQrz1/kG/uPsqyrjwfvHU1v/Kza9h4zZJzLluve3xWgMV/drtqrU6pWqer49Lf9nrdGZ6scGq8wqnxMvkow/X9XXTmr9xNql53zkxUqNadTPyeNg4zZuSzGXLRG9MAcHeOj4YTry3vypPJLP5tTBYnteibVGt1vvfKEE88O8jTPzlKpebcdFU3XR1ZJso1Jis1Jit1Jio1Jiq16cMzo4wRZYxcxshGGXKRkc1k6OyIWNHVwbKuPMu78yzvysf3OyjkIk6Mljg+WuL4aJmh0RJDI+HxqbEy1bqH86QRPvQO1OP3a0khx4ruDvp7wm3q/oru8G/Qw2cmOXJmksNnJjgyXOLImQmGRkrUHZYWc1y7rJO1y4qsXdbJ2r5Orl3WyaqlBcZKVU6OlTk5VubUeJmTYxVOjZU5MVbm9HiZk+NlTo9XOD1ept5i01ndW+T6/i5u6O+eHq7o7uDUeJkTo2VOjJVmDYcnK3R3ZOkt5untytFbzNPXmaO3M8fSYp5sZNTrTqgKxz3UQd1holwN5Rsvc2qsPL3TOTlWZrJSo7sjS3chS1dHlp6OMOzuyNKRy3B6vMLxkRJDo6Ecx0dLnBgrU2v1opoUchl6Cjl6Ctkw7MjSU8hSyEWUq2FnWqrWpu+Xq3Xq7iwt5uJtoHF76KCvM8fJ8TKDpyYYPDXOgZNhOHhqglK8feWjDKuWFli1tMA1SwusWlrkmt4CK3s66Cnkpl9rTzws5sL5VoYnqhw8PcHB0xMciocHT09w5MwkpWotnIalYRuD8DjKGB25DIVsREcuQ0c2QyEX0ZHN0JGNh7kM+SiKh5np+ZcWc/R15ejtzNPXmWdpMUcU76Tqdefg6Qn2DY2yf2iM/cdH2XcsDEcnz38FuEz8GYvMyGTCzjey8Hmbeo+7C9nZddGRpZiPwi0XboX4fiEXUarUZrbzeBud2oZK1RpLCjmWFnMsKYZhuJ+lmMsyXq4yPFFhZLLK8OTMcLRUozMX0dsZ6qC3M0dfvD33deYo1+rhMz8Struh+PN/fKREPps594kX56Bz3VykU2Nltv/oEN/cfRQIp1GY2liK+bChFHKhdVetOZV6nWrNqdbqVOphOFaqTYfaybEQlK2qvKeQpb97JrD7unJkM5nwbQEL5xlr+OZwZrwyvZFM7Rwqtdkr7unITofD1UsLrFpSoJCPOHhqggOnJjhwcpyDpyYo1879X4J8lKGvK0dfZ9hB9XWFjbWvM09vZ55l8Qd6vFRj/9Bo+AAfH2PfsVHGyue+Rm9fZ47l3R0sKWQZK4UP2+nxynnLcj7FXMSyrvChWtaVpyMbMV6uMlaqMlKqMjoZ7k+VqSObYUV3Byt6OuiPA3dFTxjmshncnXp9aucaQrBWd0rVOiOTFUZLVYYnq4xMVsPjySqT1Rod2Yh8lCGfDeE4NcyYcXqiwonREifHypyeqLTcDno7c6zpK7KmN+yIV/cWMTMOnQnhfPj0JIeHw/3m97tRxiAXZaZ3FI3v5zW9Ba5eWqSYjzCmzh1n8bYWHtfqUKrWKFXCTqtUrTNZmRmWq3XKtfp5yzDFLDRMlhSzHBsuzSrTkkKW6+NGwbLOc5+ywoFa3anH70PdnXodah4+Z6OlGqOl8L6MTlan358L/Z9MVz6irys0yPLZDMMTIbzPTFQYP8/2XMxF8Y4/7FwmKjVOxQ2i89VRPpuJP/d5VnR3sLqvyB9sffMFlXmKum4uUl9Xng+/fR0ffvu6eVtnre6cHg8t5IlyjeXxG1zInecMlQm4h26HoZESZrBqaZHuBF00tbpzdHiSAyfHOTI8SU8hy7KuDpZ15lnWnacrH11Ut5S7c2ykxL5jo5wYK5/Vgs226P5wdyYr9enQPz1Rpl4PoUXcdZKZ7k4JO95lXaHVmLT+anWnXK1TyGUWtLutWqtzarwy/e2ptzPH6r4iSwrJzmBYrzsnxsoMjZRCuJVCi3Iq6EYmq0xWaly1pMDqviLX9Iadxnx3AU3VZzn+FjNRqXE6/mY1NZwKvDMTFVb2dIRgX9HFDSu7Wd6Vv6zvQ7kavn1PVmrhG3k1DKfG5aOIvq4cy7s66O3MnXc7qtTqDE9UGI4bDd0dWZYUwze7c3XnuTvj5RqnJ8I349PjFfLZTAj2ng56OrJvyHaoFr2ISApc8tkrRUTkyqWgFxFJOQW9iEjKKehFRFJOQS8iknIKehGRlFPQi4iknIJeRCTlFuUfpsxsCPjpRS6+Ajg+j8VJG9XP3FRH56f6mdtC1NF17t7y8nyLMugvhZkNnOvfYaL6SUJ1dH6qn7kttjpS142ISMop6EVEUi6NQf/oQhdgkVP9zE11dH6qn7ktqjpKXR+9iIjMlsYWvYiINFDQi4ikXGqC3sw2m9keM9trZg8vdHkWAzN7zMyOmdmPG8YtM7OnzeyVeNi3kGVcSGa21sz+xsx2m9kuM3swHq86iplZwcz+3sx+FNfRf4jHq44amFlkZs+b2dfjx4uqflIR9GYWAY8AW4CNwL1mtnFhS7Uo/E9gc9O4h4FvufsG4Fvx43ZVBX7H3d8E3Al8NN5uVEczSsC73f2twK3AZjO7E9VRsweB3Q2PF1X9pCLogTuAve6+393LwOPA1gUu04Jz9+8BJ5tGbwX+PL7/58AH38gyLSbuftjdn4vvjxA+qKtRHU3zYDR+mItvjupompmtAd4HfL5h9KKqn7QE/WrgQMPjwXicnO0qdz8MIeiAlQtcnkXBzNYBtwE/RHU0S9wt8QJwDHja3VVHs30G+ARQbxi3qOonLUHf6jLqOm5UEjGzbuCrwEPuPrzQ5Vls3L3m7rcCa4A7zOzNC1ykRcPM3g8cc/dnF7os55OWoB8E1jY8XgMcWqCyLHZHzexqgHh4bIHLs6DMLEcI+S+5+9fi0aqjFtz9NPAdwu8+qqPgLuADZvYaocv43Wb2lyyy+klL0O8ENpjZejPLA/cA2xe4TIvVduDD8f0PA/93AcuyoMzMgC8Au939jxsmqY5iZtZvZr3x/SJwN/ASqiMA3P333H2Nu68j5M633f1DLLL6Sc0/Y83slwl9ZRHwmLv/x4Ut0cIzsy8Dv0Q4ZepR4FPAXwFfAa4FXgd+1d2bf7BtC2b2C8DfAi8y07/6SUI/veoIMLO3EH5MjAgNw6+4+x+Y2XJUR7OY2S8BH3f39y+2+klN0IuISGtp6boREZFzUNCLiKScgl5EJOUU9CIiKaegFxFJOQW9iEjKKehFRFLu/wMvoohEE+OxXQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(test_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отложенная выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final validation Loss 0.041859667748212814\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    images = valid.tensors[0].float().to(device)\n",
    "    labels = valid.tensors[1].to(device)\n",
    "    output = model(images.unsqueeze(1))  \n",
    "    loss = criterion(output, labels)\n",
    "    print('Final validation Loss {}'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_acc = torch.sum(torch.argmax(nn.functional.softmax(output, dim=1), dim=1) == labels) / valid.tensors[0].size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final validation Accuracy 98.7699966430664 %\n"
     ]
    }
   ],
   "source": [
    "print('Final validation Accuracy {} %'.format(valid_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'mnist-cnn-model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (bn1): BatchNorm1d(3136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=3136, out_features=1000, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (drop_out2): Dropout(p=0.1, inplace=False)\n",
       "  (bn2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=1000, out_features=500, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (drop_out3): Dropout(p=0.2, inplace=False)\n",
       "  (bn3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
